# Feature 0007: AI-Powered SQL Query Generation for Chat Interface

## Description
Transform the chat interface from limited context sampling (currently 10-30 records) to intelligent SQL query generation using OpenAI's natural language processing capabilities. The system will process user prompts into optimized SQL queries that retrieve relevant data from the SQLite database, providing faster responses with complete dataset access. OpenAI will analyze user intent, generate appropriate SQL queries, execute multiple queries when needed, and provide smart contextual responses based on comprehensive data analysis.

## Problem Statement
The current chat interface is limited by:
- Fixed pagination limits (10 records default, max 30 for AI context)
- Manual filter extraction that misses complex query intentions
- Context sampling that may miss relevant data points
- No ability to perform complex aggregations or multi-table queries
- Inefficient data transfer for statistical queries that only need aggregated results

## Files to Create

### lib/query-generator.ts
- **Purpose**: Natural language to SQL query conversion using OpenAI
- **Key Functions**:
  - `generateSQLFromPrompt(prompt: string): Promise<QueryPlan>`
  - `validateQuery(sql: string): boolean`
  - `optimizeQuery(sql: string): string`
- **Algorithm**:
  1. Send user prompt to OpenAI with database schema context
  2. Request structured JSON response with SQL query and execution plan
  3. Validate generated SQL for safety (no DML operations, whitelisted functions)
  4. Optimize query with proper indexes and query hints
  5. Return QueryPlan with SQL, expected result type, and execution strategy
- **Schema Context**: Include table schemas, indexes, and sample data in OpenAI prompt
- **Safety**: Whitelist allowed SQL operations, prevent data modification queries

### lib/intelligent-context.ts
- **Purpose**: Smart context selection based on query results and user intent
- **Key Functions**:
  - `buildIntelligentContext(queryResults: any[], userPrompt: string): AIContextData`
  - `determineContextStrategy(prompt: string): ContextStrategy`
  - `aggregateDataForAI(results: any[], aggregationType: string): any`
- **Context Strategies**:
  - Statistical: Pre-aggregate numbers for mathematical queries
  - Comparative: Group data by categories for comparison queries
  - Detailed: Include specific records for investigative queries
  - Temporal: Time-series data for trend analysis queries
- **Optimization**: Only include data types that match the query intent

### lib/database/query-executor.ts
- **Purpose**: Safe SQL execution with result optimization
- **Key Functions**:
  - `executeSafeQuery(sql: string, params: any[]): Promise<QueryResult>`
  - `executeMultipleQueries(queries: QueryPlan[]): Promise<QueryResult[]>`
  - `optimizeResultsForAI(results: any[], strategy: ContextStrategy): any`
- **Safety Features**:
  - Query timeout limits (5 seconds max)
  - Result size limits (max 10MB)
  - Read-only transaction enforcement
  - SQL injection prevention through parameterized queries
- **Performance**: Connection pooling, query caching for repeated patterns

### lib/types.ts (Additions)
- **New Interfaces**:
  - `QueryPlan`: { sql: string, params: any[], resultType: string, contextStrategy: ContextStrategy }
  - `ContextStrategy`: 'statistical' | 'comparative' | 'detailed' | 'temporal'
  - `QueryResult`: { data: any[], metadata: QueryMetadata, executionTime: number }
  - `QueryMetadata`: { rowCount: number, columns: string[], aggregations?: any }

## Files to Modify

### app/api/chat/route.ts
- **Current State**: Uses simple filter-based context retrieval with 10-30 record limit
- **Modifications**:
  1. Replace `getDataContext()` with `generateSQLFromPrompt()` call
  2. Add query execution pipeline: prompt → SQL generation → query execution → context building
  3. Implement multi-query support for complex questions requiring multiple data perspectives
  4. Add query result caching to prevent redundant database calls
  5. Enhanced error handling for SQL generation and execution failures
- **New Flow**:
  1. Send user prompt to OpenAI for SQL generation
  2. Validate and execute generated SQL query
  3. Build intelligent context based on query results and user intent
  4. Send optimized context to OpenAI for final response generation

### lib/ai-context.ts
- **Current State**: Simple filter extraction and limited context sampling
- **Modifications**:
  1. Remove manual filter extraction logic (replace with AI-generated SQL)
  2. Update `getDataContext()` to accept SQL query results instead of filter-based search
  3. Add intelligent context building based on query result patterns
  4. Implement dynamic context sizing based on data complexity
  5. Add support for pre-aggregated statistical data to reduce token usage

### lib/database/search.ts
- **Current State**: Basic filter-based search with pagination
- **Additions**:
  1. Add `executeCustomQuery()` function for AI-generated SQL
  2. Implement query result optimization for different AI context strategies
  3. Add query performance monitoring and optimization suggestions
  4. Create query validation utilities for AI-generated SQL

### components/ChatInterface.tsx
- **Current State**: Basic SSE streaming with fixed response format
- **Modifications**:
  1. Add loading states for query generation phase
  2. Display query execution progress for complex queries
  3. Add query explanation feature (show generated SQL to advanced users)
  4. Implement query result preview for verification before AI analysis
  5. Add multi-query progress indicators when OpenAI requests multiple queries

## Technical Implementation

### OpenAI SQL Generation System
- **Model**: Use GPT-4 for complex SQL generation (more reliable than GPT-3.5 for structured queries)
- **Prompt Engineering**:
  - Include complete database schema with relationships
  - Provide example queries for common patterns
  - Request structured JSON response format
  - Include safety instructions (read-only operations only)
- **Response Format**:
  ```json
  {
    "queries": [
      {
        "sql": "SELECT AVG(inspection_score) FROM inspections WHERE city = ?",
        "params": ["Houston"],
        "purpose": "Calculate average inspection score for Houston",
        "resultType": "aggregation"
      }
    ],
    "contextStrategy": "statistical",
    "explanation": "This query calculates the average inspection score for Houston pipes"
  }
  ```

### Database Schema Context for AI
- **Tables**: inspections, defects with complete column definitions
- **Indexes**: Available indexes for query optimization suggestions
- **Sample Data**: Representative data samples for AI understanding
- **Relationships**: Foreign key relationships between tables
- **Constraints**: Data validation rules and value ranges

### Multi-Query Support
- **Query Chaining**: Support for dependent queries where results from query 1 inform query 2
- **Parallel Execution**: Execute independent queries simultaneously for better performance
- **Result Correlation**: Combine results from multiple queries into coherent context
- **Transaction Management**: Ensure all queries run in same read-only transaction for consistency

### Safety and Performance Measures
- **SQL Whitelist**: Only allow SELECT statements with approved functions
- **Query Timeout**: 5-second maximum execution time per query
- **Result Limits**: Maximum 10,000 rows per query, 10MB total result size
- **Rate Limiting**: Maximum 5 queries per chat interaction
- **Validation**: Parse and validate SQL before execution
- **Monitoring**: Log query performance and OpenAI API usage

### Error Handling Strategy
- **SQL Generation Errors**: Fallback to current filter-based approach
- **Query Execution Errors**: Provide user-friendly error messages with query simplification suggestions
- **Performance Issues**: Query timeout with partial results and optimization suggestions
- **OpenAI API Limits**: Graceful degradation to simpler context when API unavailable

## Expected Performance Improvements
- **Complete Dataset Access**: No more 10-30 record limitations, full database querying capability
- **Optimized Data Transfer**: Only relevant aggregated data sent to AI, reducing token usage by 60-80%
- **Faster Response Times**: Direct SQL execution vs. streaming file processing (estimated 5-10x faster)
- **Enhanced Query Capabilities**: Support for complex aggregations, joins, and statistical analysis
- **Smart Context**: Query-specific context selection improving response relevance by 40-50%

## Database Schema Context for OpenAI
```sql
-- Tables: inspections, defects
-- Key columns: city, state, material, inspection_score, requires_repair, timestamp_utc
-- Common queries: COUNT, AVG, GROUP BY, WHERE conditions
-- Sample aggregations: material performance, geographic trends, repair priorities
```

## Integration with Existing System
- **Backward Compatibility**: Keep current search API as fallback for UI components
- **Gradual Migration**: Chat interface uses new system, other components unchanged
- **Performance Monitoring**: Compare new vs. old system performance metrics
- **Configuration**: Feature flag to switch between old and new chat systems
