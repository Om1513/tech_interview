# Feature 0006: SQLite Database Integration with Streaming Data Import

## Description
Implement SQLite database integration to store and cache sewer inspection data locally, replacing the current S3-only streaming approach. This will enable faster queries, offline capabilities, and better data management while maintaining the ability to import new data from S3 streams.

## Test Data Analysis
Based on the provided test data structure:
```json
{
  "id": "insp_00000000",
  "timestamp_utc": "2020-07-22T16:16:18.077Z",
  "inspection_type": "Post-cleaning",
  "location": {
    "city": "Chicago", "state": "KS", "district": "District 14",
    "street": "Kreiger Villages", "gps": {"lat": 63.2001, "lon": -67.4698},
    "upstream_manhole": "CB-35824N", "downstream_manhole": "JB-32191W"
  },
  "pipe": {
    "material": "DIP", "material_desc": "Ductile Iron Pipe",
    "diameter_in": 18, "length_ft": 228, "age_years": 37,
    "shape": "Circular", "install_year": 1983, "slope_percent": 1.76
  },
  "conditions": {"weather": "Overcast", "flow": "Low", "debris_level": "None", "access_difficulty": "Moderate"},
  "equipment": {"type": "Zoom Camera", "model": "Jacobs and Sons D8Z-1064", "camera_id": "CAM497"},
  "defects": [],
  "observations": {"roots": "None", "grease": "None", "debris": "Heavy", "corrosion": "Heavy"},
  "sensor_data": {"flow_rate_mgd": 11.26, "velocity_fps": 2.1, "depth_in": 34.5, "temperature_f": 79.5, "ph": 7.7, "dissolved_oxygen_ppm": 4.1, "turbidity_ntu": 59.8, "h2s_ppm": 0},
  "inspection_score": 100, "severity_max": 0,
  "crew": {"inspector_id": "INS617", "inspector_name": "Brandi Hirthe", "crew_size": 4, "contractor": "Waters - Schaden"},
  "duration_minutes": 42, "video_file": "VID_20200722_000000.mp4",
  "report_generated": false, "requires_cleaning": false, "requires_repair": false,
  "notes": null, "qc_reviewed": false, "tags": ["commercial", "main-line"]
}
```

## Files to Create and Modify

### 1. Database Schema Update (prisma/schema.prisma)
- **Change datasource**: Switch from PostgreSQL to SQLite
- **Update generator**: Configure for SQLite compatibility
- **Define inspection schema**: Create comprehensive table structure
- **Add indexes**: Optimize for common search patterns
- **Define relationships**: Handle defects and related data

### 2. Database Service (lib/database/sqlite.ts)
- **Purpose**: Core SQLite operations and connection management
- **Functions**:
  - `initializeDatabase()`: Create database and tables
  - `insertInspection(inspection: SewerInspection)`: Insert single record
  - `insertInspectionsBatch(inspections: SewerInspection[])`: Bulk insert with transactions
  - `getInspections(filters: SearchFilters, page, pageSize)`: Paginated search
  - `getInspectionCount(filters: SearchFilters)`: Count matching records
  - `createIndexes()`: Performance optimization indexes

### 3. Data Import Service (lib/database/importer.ts)
- **Purpose**: Stream and import data from S3 to SQLite
- **Functions**:
  - `importFromS3(fileName: string, batchSize: number)`: Import single file
  - `importAllFiles(progressCallback?)`: Import all S3 files
  - `syncWithS3(lastSyncTime?)`: Incremental sync
  - `validateImportedData()`: Data integrity checks
- **Features**:
  - Batch processing for performance
  - Progress tracking and callbacks
  - Duplicate detection and handling
  - Error recovery and retry logic

### 4. Database Search Service (lib/database/search.ts)
- **Purpose**: Replace S3 streaming search with SQLite queries
- **Functions**:
  - `searchInspections(filters: SearchFilters, page, pageSize)`: Main search function
  - `buildWhereClause(filters: SearchFilters)`: Dynamic SQL generation
  - `getSearchStats(filters: SearchFilters)`: Aggregation queries
  - `getUniqueValues(field: string)`: For dropdown options
- **Features**:
  - SQL injection prevention
  - Performance optimization
  - Complex filter combinations
  - Full-text search capabilities

### 5. Migration Service (lib/database/migration.ts)
- **Purpose**: Handle database migrations and updates
- **Functions**:
  - `getCurrentVersion()`: Check database version
  - `runMigrations()`: Execute pending migrations
  - `backupDatabase()`: Create backups before migrations
  - `validateSchema()`: Ensure schema integrity

### 6. Database CLI Tool (scripts/db-import.ts)
- **Purpose**: Command-line tool for data management
- **Commands**:
  - `npm run db:import` - Import all S3 data
  - `npm run db:sync` - Sync with S3 changes
  - `npm run db:status` - Show import status
  - `npm run db:reset` - Reset database

### 7. API Route Updates (app/api/search/route.ts)
- **Modify search endpoint**: Use SQLite instead of S3 streaming
- **Maintain API compatibility**: Same request/response format
- **Add import endpoints**: 
  - `POST /api/import/start` - Start data import
  - `GET /api/import/status` - Check import progress
  - `POST /api/import/sync` - Sync with S3

### 8. Import UI Component (components/ImportManager.tsx)
- **Purpose**: Admin interface for data import management
- **Features**:
  - Import progress visualization
  - Import status indicators
  - Manual sync triggers
  - Import history and logs

### 9. Database Configuration (lib/database/config.ts)
- **Purpose**: SQLite configuration and optimization
- **Settings**:
  - Performance tuning (WAL mode, cache settings)
  - Connection pooling
  - Backup strategies
  - Maintenance schedules

## Database Schema Design

### Primary Tables:

#### inspections
```sql
CREATE TABLE inspections (
  id TEXT PRIMARY KEY,
  timestamp_utc DATETIME NOT NULL,
  inspection_type TEXT,
  
  -- Location fields (flattened for performance)
  city TEXT NOT NULL,
  state TEXT NOT NULL,
  district TEXT,
  street TEXT,
  gps_lat REAL,
  gps_lon REAL,
  upstream_manhole TEXT,
  downstream_manhole TEXT,
  
  -- Pipe fields (flattened for performance)
  material TEXT NOT NULL,
  material_desc TEXT,
  diameter_in INTEGER NOT NULL,
  length_ft REAL NOT NULL,
  age_years INTEGER,
  shape TEXT,
  install_year INTEGER,
  slope_percent REAL,
  
  -- Core inspection data
  inspection_score INTEGER NOT NULL,
  severity_max INTEGER DEFAULT 0,
  requires_repair BOOLEAN NOT NULL,
  requires_cleaning BOOLEAN,
  
  -- JSON fields for complex data
  conditions TEXT, -- JSON
  equipment TEXT, -- JSON
  observations TEXT, -- JSON
  sensor_data TEXT, -- JSON
  crew TEXT, -- JSON
  
  -- Additional fields
  duration_minutes INTEGER,
  video_file TEXT,
  report_generated BOOLEAN,
  notes TEXT,
  qc_reviewed BOOLEAN,
  tags TEXT, -- JSON array
  
  -- Metadata
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  updated_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  imported_at DATETIME DEFAULT CURRENT_TIMESTAMP
);
```

#### defects
```sql
CREATE TABLE defects (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  inspection_id TEXT NOT NULL,
  code TEXT NOT NULL,
  description TEXT NOT NULL,
  severity INTEGER NOT NULL,
  distance_ft REAL NOT NULL,
  category TEXT,
  clock_start INTEGER,
  clock_end INTEGER,
  dimensions TEXT, -- JSON
  photo_ref TEXT,
  video_timestamp_sec INTEGER,
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP,
  FOREIGN KEY (inspection_id) REFERENCES inspections(id)
);
```

#### import_log
```sql
CREATE TABLE import_log (
  id INTEGER PRIMARY KEY AUTOINCREMENT,
  source_file TEXT NOT NULL,
  started_at DATETIME NOT NULL,
  completed_at DATETIME,
  records_processed INTEGER DEFAULT 0,
  records_imported INTEGER DEFAULT 0,
  errors INTEGER DEFAULT 0,
  status TEXT DEFAULT 'running', -- running, completed, failed
  error_message TEXT,
  created_at DATETIME DEFAULT CURRENT_TIMESTAMP
);
```

### Performance Indexes:
```sql
CREATE INDEX idx_inspections_city ON inspections(city);
CREATE INDEX idx_inspections_state ON inspections(state);
CREATE INDEX idx_inspections_material ON inspections(material);
CREATE INDEX idx_inspections_score ON inspections(inspection_score);
CREATE INDEX idx_inspections_repair ON inspections(requires_repair);
CREATE INDEX idx_inspections_timestamp ON inspections(timestamp_utc);
CREATE INDEX idx_inspections_location ON inspections(city, state);
CREATE INDEX idx_defects_inspection ON defects(inspection_id);
CREATE INDEX idx_defects_severity ON defects(severity);
```

## Implementation Phases

### Phase 1: Database Setup and Schema
1. Update Prisma schema for SQLite
2. Create database initialization scripts
3. Implement core database service
4. Add migration system
5. Create database configuration

### Phase 2: Import System
1. Build data import service with streaming
2. Implement batch processing and transactions
3. Add progress tracking and error handling
4. Create CLI tools for import management
5. Add data validation and integrity checks

### Phase 3: Search Integration
1. Replace S3 search with SQLite queries
2. Maintain API compatibility
3. Optimize query performance
4. Add full-text search capabilities
5. Update frontend components

### Phase 4: Management Interface
1. Create import management UI
2. Add import status monitoring
3. Implement sync functionality
4. Add database statistics and health checks
5. Create admin tools and utilities

## Import Algorithm

### Streaming Import Process:
1. **Initialize**: Create database connection and prepare statements
2. **Stream File**: Read S3 file in chunks (200 records)
3. **Transform**: Convert JSON to database format
4. **Validate**: Check data integrity and required fields
5. **Batch Insert**: Use transactions for performance (100 records per batch)
6. **Progress**: Update import log and notify UI
7. **Complete**: Finalize import and update statistics

### Duplicate Handling:
- Use `INSERT OR REPLACE` for upsert behavior
- Check `id` field for existing records
- Log duplicate actions for audit trail

### Error Recovery:
- Transaction rollback on batch failures
- Retry logic for temporary failures
- Detailed error logging with context
- Ability to resume interrupted imports

## Performance Considerations

### Database Optimization:
- **WAL Mode**: Write-Ahead Logging for better concurrency
- **Memory Settings**: Optimize cache and temp storage
- **Batch Size**: 100-200 records per transaction
- **Indexes**: Strategic indexing for search patterns
- **VACUUM**: Regular maintenance operations

### Query Performance:
- **Prepared Statements**: Prevent SQL injection and improve performance
- **Connection Pooling**: Reuse database connections
- **Query Planning**: Analyze and optimize common queries
- **Pagination**: Efficient LIMIT/OFFSET alternatives

## Integration with Existing Code

### Backward Compatibility:
- Maintain existing API endpoints and formats
- Keep S3 streaming as fallback option
- Gradual migration path
- Feature flags for database vs S3 mode

### Search Function Updates:
- Replace `searchInspections()` implementation
- Keep same function signature and return format
- Add database-specific optimizations
- Maintain error handling patterns

## Environment Variables

```env
# Database Configuration
DATABASE_URL="file:./data/inspections.db"
DATABASE_MODE="sqlite" # sqlite or s3-stream
DATABASE_IMPORT_BATCH_SIZE=100
DATABASE_BACKUP_ENABLED=true
DATABASE_BACKUP_INTERVAL=24h

# Import Configuration
IMPORT_AUTO_SYNC=false
IMPORT_PROGRESS_WEBHOOK_URL=""
IMPORT_MAX_RETRIES=3
```

## Success Criteria

1. **Performance**: Database searches 10x faster than S3 streaming
2. **Reliability**: 99.9% import success rate with error recovery
3. **Compatibility**: Zero breaking changes to existing API
4. **Scalability**: Handle 1M+ inspection records efficiently
5. **Maintainability**: Clear separation of concerns and testable code
