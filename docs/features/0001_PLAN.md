# Feature 0001: S3 Streaming & Data Processing

## Description
Implement S3 streaming capability to read and parse JSONL (JSON Lines) data from the 'sewerai-public' S3 bucket. This feature enables efficient streaming of large sewer inspection datasets without loading entire files into memory, supporting line-by-line parsing with configurable limits.

## Files to Create

### lib/s3-stream.ts
- **Purpose**: Core S3 streaming utilities
- **Key Function**: `streamFromS3(fileName: string, limit = 10)`
- **Dependencies**: AWS SDK v2
- **Configuration**: 
  - S3 region: 'us-west-2'
  - Bucket: 'sewerai-public'
  - Signature version: 'v4'
- **Algorithm**:
  1. Create S3 read stream for specified file
  2. Process chunks incrementally using async iteration
  3. Maintain buffer for incomplete lines
  4. Split buffer on newlines, keeping last incomplete line
  5. Parse each complete line as JSON
  6. Accumulate results until limit reached
  7. Handle JSON parsing errors gracefully
  8. Return array of parsed inspection records

### app/api/test-stream/route.ts
- **Purpose**: Test endpoint for S3 streaming functionality
- **HTTP Method**: GET
- **Response**: Array of first 10 sewer inspection records
- **Error Handling**: Catch and return streaming/parsing errors
- **Integration**: Uses `streamFromS3` function from lib/s3-stream.ts

## Files to Modify

### lib/types.ts
- **Current State**: Contains SewerInspection interface and related types
- **Modification**: Add streaming-specific types if needed:
  - StreamResult interface for API responses
  - Error types for streaming failures

## Technical Requirements

### AWS Configuration
- Use existing aws-sdk dependency (v2.1692.0)
- No additional AWS credentials setup required (assumes public bucket or environment-based auth)
- S3 client configured with us-west-2 region and v4 signatures

### Memory Management
- Stream processing to keep memory usage under 50MB
- Line-by-line processing prevents loading entire files
- Configurable limit parameter controls result set size

### Error Handling
- JSON parsing errors logged but don't stop processing
- Network/S3 errors propagated to API response
- Graceful handling of malformed JSONL data

### Data Format
- Input: JSONL files (one JSON object per line)
- Output: Array of SewerInspection objects matching existing interface
- Each line should parse to SewerInspection type structure

## Testing Strategy
- Test endpoint at `/api/test-stream` returns 10 records
- Verify console logging shows streaming progress
- Monitor memory usage stays below 50MB threshold
- Validate returned data matches SewerInspection interface
